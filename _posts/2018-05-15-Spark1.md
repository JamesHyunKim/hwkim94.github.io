---
layout: post
title:  "Spark[1] Spark: Cluster Computing with Working Sets(2010) - Review"
date:   2018-05-15 13:18:00 +0900
categories: [distributed-computing, spark, rdd, paperreview]
---

## 1. Abstract
- **기존의 Hadoop 등 분산처리 framework는 비순환적인 데이터 흐름의 모델에 적합하기 때문에, 여러 operation에 대해 data를 재사용할 경우에는 비효율적(머신러닝 등)**

- Spark
    - iterative algorithm, interactive data analysis에 효율적으로 대처하기 위한 framework
    - RDD(resilient distributed dataset) : read-only, fault-tolerant collection of partitioned object

-----

## 2. Introduction
- 기존의 분산처리 framework는 data를 재사용하는 모델에 비효율적
    - iterative job : 데이터를 재사용할 때마다 디스크에서 데이터를 불러와야함(머신러닝 등)
    - interactive analytics : SQL과 유사한 query를 통해 data를 탐색할 때, 각 query마다 데이터를 불러와야 함 

- Spark는 RDD를 통해 위의 단점을 극복
     - **RDD를 cache에 올려서 재사용할 때 효율적으로 사용가능**
     - lineage(계보)를 통하여 fault-tolerant : RDD에 문제가 생기면 다시 만들 수 있는 밑그림

-----

## 3. Programming Model
# 3.1 Resilient Distributed Datasets(RDDs) 
- read-only
    - RDD 자체를 바꾸지 않으므로, RDD를 어떻게 만드는지 방법(lineage)을 알면 항상 만들어낼 수 있음

- lineage
    - RDD가 굳이 물리적데이터로 존재할 필요 없이, 어떻게 만들어지는지에 대한 정보만 가지고 있어도 됨
    - 따라서 RDD에 문제가 생겼을 때, 언제든지 새롭게 compute할 수 있음

- RDD를 만드는 방법들
    - *HDFS*에서 불러오기    
    - array, list 등 python/scala 등의 언어로 생성된 collection을 RDD로 바꾸는 *parallelizing*
    - 기존의 RDD에 연산을 통해 새로운 RDD를 만들어내는 *transformation*
    - *persistence*를 통하여 lazy execution으로 RDD를 구체화하여 cache 혹은 디스크에 올리기

# 3.2 Parallel Operations
- reduce(), collect(), foreach() 등의 연산
- RDD는 구체화되지 않은 lazy RDD상태로 존재하며 reduce()등 action 연산을 통해서 구체화됨
- group연산 등을 지원할 예정

# 3.3 Shared Variables
- Broadcast Variable
    - read-only
    - look-up table과 같은 역할
    - large-scale data가 여러 연산에서 사용될 경우, 해당 데이터를 모든 node에 공유하여 필요할 때마다 각 node에서 접근

- Accumulator
    - add-only
    - driver에서만 접근 가능하며, 각 node의 task를 수집(count 등의 작업)

-----

## 4. Examples
# 4.1 Text Search
![text](https://files.slack.com/files-pri/T1J7SCHU7-FAP397J0Y/text.png?pub_secret=5668438336)

# 4.2 Logistic Regression
![lr](https://files.slack.com/files-pri/T1J7SCHU7-FAP396XNU/lr.png?pub_secret=d8a46eba6f)

# 4.3 Alternating Least Squares
![als](https://files.slack.com/files-pri/T1J7SCHU7-FAP39797A/als.png?pub_secret=5395789900)
- collaborative filtering에 사용되는 알고리즘

-----

## 5. Implementation
- RDD는 아래의 interface를 상속받아 생성
    - getPartitions()
    - getIterator(partition)
    - getPreferredLoactions(partition)

# 5.1 Shared Variable
- Broadcast variable
    - broadcast variable로 지정이 되면, hdfs 등 file system에 저장됨
    - 해당 variable을 불러올 때, 우선 value가 cache에 있는지 확인하고, 없으면 file system에서 불러옴

- Accumulator
    - 각 node에서 task가 끝나면, accumulator의 update 정보를 driver로 전송하고, driver는 이 정보들을 취합 update

# 5.2 Interpreter Integration
- 초기에는 scala interpreter에 Spark를 얹어두는 식으로 개발
    - scala가 각 line을 singleton class로 다루는 점을 활용

-----

## 6. Results
![result](https://files.slack.com/files-pri/T1J7SCHU7-FAP7TQFPT/result.png?pub_secret=ec35b6cb99)

-----

## 7. Related Work
- Distributed Shared Memory
- Cluster Computing Frameworks
- Language Integration
- Lineage

-----

## 8. Discussion and Future Work
**RDD는 cluster computation환경에서 iterative, interactive computation에 적합하다.**

-----

## 9. Reference
- [http://static.usenix.org/legacy/events/hotcloud10/tech/full_papers/Zaharia.pdf](http://static.usenix.org/legacy/events/hotcloud10/tech/full_papers/Zaharia.pdf)
- [https://www.slideshare.net/yongho/rdd-paper-review](https://www.slideshare.net/yongho/rdd-paper-review)
