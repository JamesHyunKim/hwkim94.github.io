---
layout: post
title:  "YOLO[3] YOLOv3: An Incremental Improvement(2018) - Review"
date:   2018-09-24 04:30:00 +0900
categories: [deeplearning, cnn, image-detection, yolo, paperreview]
---

## 1. Abstract
- YOLOv3
    - YOLOv2보다 조금 더 큰 model
    - 성능 향상
    - 빠른 속도

-----

## 2. Introduction
- tech report 형식
    - 이것저것 시도했던 내용들이 적혀있는 tech report
- YOLOv3는 YOLOv2를 조금 개선한 모델

-----

## 3. The Deal
- 다른 논문들의 idea를 사용하여 YOLOv2를 개선

# 3.1 Bounding Box Prediction
![fig2](https://files.slack.com/files-pri/T1J7SCHU7-FCYMBBV8R/fig2.png?pub_secret=81ea348441)
- box coordinate prediction
    - $$t_x$$ = $$\sigma^{-1} (b_x-c_x)$$
    - $$t_y$$ = $$\sigma^{-1} (b_y-c_y)$$
    - $$t_w$$ = $$ln (b_w / p_w)$$
    - $$t_h$$ = $$ln (b_h / p_h)$$
    - 기존의 식에 inverse를 취해서 ground truth $$t$$ = $$(t_x, t_y, t_w, t_h)$$를 계산하고, box coordinate prediction을 통해 $$\hat{t}$$ 를 직접 예측하는 방식을 사용

- objectness score의 threshold를 0.5로 사용하여, threshold를 넘는 bounding box만 사용
- 따라서, 만약 bounding box가 ground-truth box에 할당되지 않으면 objectness score에 대한 학습만 이뤄지고, coordinate 등에 관한 학습은 이뤄지지 않음

# 3.2 Class Prediction
- YOLOv2는 softmax를 사용했지만, 'woman'과 'person' 같이 배타적이지 않은 label도 있으므로 softmax를 사용하면 비효율적
- YOLOv3에서는 multi-label approach를 선택
    - 각각의 label에 대하여 독립적으로 logistic classification
    - binary cross entropy를 통해 loss를 계산하여 학습
    - threshold를 설정하여 multi-label classification 수행

# 3.3 Predictions Across Scales
- k-means clustering으로 생성한 9개의 anchor box 사용
    -매 학습마다 9개의 anchor box 중에서 임의로 3개의 anchor box 사용하여 학습

- multi-scale
    - 이전 2번째 layer와 제일 앞단의 layer를 upsampling하여 concatenate하고 convolution layer로 feature map을 combine
    - 이렇게 생성된 앞단의 feature map과 원래의 feature map을 사용하여 최종적인 anchor box의 정보를 예측
    - 따라서, 더 높은 해상도의 정보를 가져올 수 있으므로 작은 object를 잘 예측할 수 있게 됨
    - 또한, 3개의 scale에 대해서 학습한 효과를 가짐

# 3.4 Feature Extractor
![table1-2](https://files.slack.com/files-pri/T1J7SCHU7-FD0AMULLF/table1.png?pub_secret=a091c556ab)
- Darknet에 shortcut connection을 적용
    - 더 깊은 layer를 가지게 되어 모델의 크기가 커짐 
    - 기존의 Darknet-19보다는 강력하고, resNet-101보다는 효율적인 성능 

# 3.5 Training
- multi-scale training, data augmentation, batch normalization 등등의 기법을 사용

-----

## 4. How We Do
![table3](https://files.slack.com/files-pri/T1J7SCHU7-FCZECP8PP/table3.png?pub_secret=b29de35b1f)
![fig](https://files.slack.com/files-pri/T1J7SCHU7-FCYHDSK2L/fig1.png?pub_secret=bcd3137996)
- metric에 따라 다른 성능을 보여줌
    - COCO의 새로운 metric에 대해서는 성능이 안좋지만, 기존의 metric에서는 성능이 아주 좋음
    - metric의 IoU threshold가 높아질록 성능이 안좋아짐
    - 즉, YOLO와 YOLOv3는 작은 object를 못찾았지만, YOLOv3는 큰 object를 잘 못찾게 됨

- 다른 model보다 훨씬 빠른 속도를 보여줌

-----

## 5. Things We Tried That Didn’t Work
- Anchor box x, y offset predictions
- Linear x, y predictions instead of logistic
- Focal loss
    - RetinaNet에서 제안한 loss
    - background와 object에 대한 loss를 분리하여 적용
    - YOLO는 backgound가 class에 없으며, 이미 loss를 분리하여 적용하고 있으므로 큰 효과가 없음
- Dual IOU thresholds and truth assignment
    - Faster R-CNN처럼 IoU의 기준을 2개로 사용하는 것
    - Faster R-CNN의 경우 0.7 이상은 positive, 0.3 이하는 negative로 setting

-----

## 6. What This All Means
- YOLOv3는 빠르고 정확하다.
- 연구 윤리를 지켜야한다.

-----

## 7. Reference
- [https://pjreddie.com/media/files/papers/YOLOv3.pdf](https://pjreddie.com/media/files/papers/YOLOv3.pdf)
- [http://dhhwang89.tistory.com/138](http://dhhwang89.tistory.com/138)
- [https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b](https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b)
